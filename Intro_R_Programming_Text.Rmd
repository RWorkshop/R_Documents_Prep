---
title: "Introduction to the R Programming Language"
output: html_document
---

# The R Programming Language

R is a free software environment for statistical computing and graphics. It is widely used for:

- Data analysis
- Statistical modeling
- Simulation and visualization
- Scientific computing

---

# Vector Types in R

R operates on named data structures. The most basic is the **vector**, which is an ordered collection of values.

There are several types of vectors:

- Numeric vectors  
- Character vectors  
- Logical vectors  
- (Others include complex vectors and color vectors)

### Creating Vectors

```r
# Numeric vector
NumVec <- c(10.4, 5.6, 3.1, 6.4)

# Character vector
CharVec <- c("blue", "green", "yellow")

# Logical vector
LogVec <- c(TRUE, FALSE)

# Using assign()
assign("z", c(1, 2, 3))
```

---

# Set Theory Operations

```r
a <- c(1, 2, 3, 4)
b <- c(3, 4, 5, 6)

union(a, b)
intersect(a, b)
setdiff(a, b)
```

---

# Controlling Precision and Integerization

```r
pi
round(pi, 3)
round(pi, 2)
floor(pi)
ceiling(pi)
as.integer(pi)
```

---

# Important Introductory Functions

```r
head(mtcars)   # First few rows
tail(iris)     # Last few rows
```

---

# Writing Functions in R

### General Syntax

```r
function_name <- function(arg1, arg2 = default, ...) {
  # Commands
  result <- ...
  return(result)
}
```

### Example 1: Square Function

```r
sf1 <- function(x) {
  x^2
}

sf1(3)              # returns 9
x.sq <- sf1(3)      # store result
```

### Example 2: Pythagorean Distance

```r
sf2 <- function(a1, a2, a3) {
  x <- sqrt(a1^2 + a2^2 + a3^2)
  return(x)
}

res <- sf2(2, 3, 4)
res
```

### Example 3: Power Function with Defaults

```r
mypower <- function(x, pow = 2) {
  x^pow
}

mypower(4)            # returns 16
mypower(4, 3)         # returns 64
mypower(pow = 5, x = 2)  # returns 32
```

---

# Statistical Tests and ANOVA Interpretation

R provides tools for linear regression and ANOVA output.

### Test for the Slope

Given:
```r
beta_hat <- 2.4
se_beta <- 0.3
t_stat <- beta_hat / se_beta
t_stat
```

### Residual Checking

Use diagnostic plots to validate model assumptions:

```r
model <- lm(mpg ~ wt, data = mtcars)
par(mfrow = c(2, 2))
plot(model)
```

---

# Confidence Intervals Example

```r
xbar <- 83
sigma <- 12
n <- 5
sem <- sigma / sqrt(n)

lower <- xbar + sem * qnorm(0.025)
upper <- xbar + sem * qnorm(0.975)

c(lower, upper)
```

---

# Chi-Square Test

```r
table_data <- matrix(c(12, 5, 7, 16), nrow = 2)
chisq.test(table_data)
```

---

# Creating and Importing Data

### From Excel

```r
library(gdata)
mydata <- read.xls("mydata.xls")
```

### From CSV

```r
mycsv <- read.csv("data.csv")
write.csv(mycsv, "output.csv")
```

---

# Data Entry with `scan()`

```r
nums <- scan()   # input: 1 2 3 4 ENTER
```

---

# Classes of Data Objects

```r
class(NumVec)
class(CharVec)
class(mtcars)
```

---

Let me know if youâ€™d like this saved as an .Rmd file, or if you'd like to split it up into multiple lessons or chapters!
```

---




\newpage
\chapter{Programming}

\section{Writing Functions}

A simple function can be constructed as follows:

\begin{verbatim}
function_name <- function(arg1, arg2, ...){
commands
output
}
\end{verbatim}

You decide on the name of the function. The function command shows R that you are writing a function. Inside the parenthesis you outline the input objects required and decide what to call them. The commands occur inside the { }.

The name of whatever output you want goes at the end of the function. Comments lines (usually a description of what the function does is placed at the beginning) are denoted by "\#".

\begin{verbatim}sf1 <- function(x){
x^2
}
\end{verbatim}

This function is called sf1. It has one argument, called x.
Whatever value is inputted for x will be squared and the result outputted to the screen. This function must be loaded into ``R} and can then be called. We can call the function using:
\begin{verbatim}
sf1(x = 3)
#sf1(3)
[1] 9
To store the result into a variable x.sq
x.sq <- sf1(x = 3)
x.sq <- sf1(3)
> x.sq
[1] 9
\end{verbatim}
Example
\begin{verbatim}
sf2 <- function(a1, a2, a3){
x <- sqrt(a1^2 + a2^2 + a3^2)
return(x)
}
\end{verbatim}

This function is called sf2 with 3 arguments. The values inputted for a1, a2, a3 will be squared, summed and the square root of the sum calculated and stored in x. (There will be no output to the screen as in the last example.)
The return command specifies what the function returns, here the value of x. We will not be able to view the result of the function unless we store it.
\begin{verbatim}sf2(a1=2, a2=3, a3=4)
sf2(2, 3, 4) # Can't see result.
res <- sf2(a1=2, a2=3, a3=4)
res <- sf2(2, 3, 4) # Need to use this.
res
[1] 5.385165
\end{verbatim}
We can also give some/all arguments default values.
\begin{verbatim}mypower <- function(x, pow=2){
x^pow
}
\end{verbatim}
If a value for the argument pow is not specified in the function call,
a value of 2 is used.
\begin{verbatim}mypower(4)
[1] 16
\end{verbatim}
If a value for "pow" is specified, that value is used.
\begin{verbatim}
mypower(4, 3)
[1] 64
mypower(pow=5, x=2)
[1] 32
\end{verbatim}








%----------------------------------------------------%


\large \begin{verbatim}
> code here
\end{verbatim}\large


\large \begin{verbatim}
> code here
\end{verbatim}\large



%---------------------------------------------------%
\subsubsection{slide234}
The TS are <equation here>  
The p-values for both of these tests are 0 and so there is enough evidence to reject $H_0$ and conclude that both 0 and 1 are not 0, i.e. there is a significant linear relationship between x and y. 
Also given are the $R^2$ and $R^2$ adjusted values. Here $R^2 = SSR/SST = 0.8813$ and so $88.13\%$ of the variation in y is being explained by x. 
The final line gives the result of using the ANOVA table to assess the model t.

%----------------------------------------------------%

\subsubsection{slide235}

In SLR, the ANOVA table tests <EQN>The TS is the F value and the critical value and p-values are found
in the F tables with (p - 1) and (n - p) degrees of freedom.

This output gives the p-value = 0, therefore there is enough evidence to reject H0 and conclude that there is a signicant linear relationship between y and x. The full ANOVA table can be accessed using :

<TABLE HERE>



\subsubsection{slide236}
Once the model has been tted, must then check the residuals.
The residuals should be independent and normally distributed with
mean of 0 and constant variance.
A Q-Q plot checks the assumption of normality (can also use a
histogram as in MINITAB) while a, plot of the residuals versus fitted values gives an indication as to whether the assumption of constant variance holds.

<HISTOGRAM>


%----------------------------------------------------%
\subsubsection{slidename}

\large \begin{verbatim}
> xbar <- 83
> sigma <- 12
> n <- 5
> sem <- sigma/sqrt(n)
> sem
[1] 5.366563
> xbar + sem * qnorm(0.025)
[1] 72.48173
> xbar + sem * qnorm(0.975)
[1] 93.51827
\end{verbatim}\large


\subsubsection{Testing the slope (II)}

You can compute a
t test for that hypothesis simply by dividing the estimate by its standard
error
\begin{equation}
t = \frac{\hat{\beta}}{S.E.(\hat{\beta})}
\end{equation}
which follows a t distribution on n - 2 degrees of freedom if the true $\beta$ is
zero.


%----------------------------------------------------%
\begin{itemize}
*  The standard $\chi^{2}$ test  in chisq.test works with data in matrix form, like fisher.test does.
*  For a 2 by 2 table, the test is exactly equivalent to prop.test.
\end{itemize}


\large \begin{verbatim}
> chisq.test(lewitt.machin)
\end{verbatim}\large

