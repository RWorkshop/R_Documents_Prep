

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Setting up project directories

It is helpful to organize your work in project directories.
Create a directory for your project.
Copy a workspace (a .Rdata file) to the directory
You can then start R by clicking on the .Rdata file's icon
All directory references in the R session will be relative to the project directory. For example, you can read a file 'data.csv' in the directory with


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
http://www.r-tutor.com/elementary-statistics/hypothesis-testing/two-tailed-test-population-proportion
 


Regression more

http://www.ats.ucla.edu/stat/R/dae/rreg.htm


 

Chi-square Tests
Hypothesis test for count data that use the Pearson Chi-square statistic are available in R.
These include the goodness-of-fit tests and those for contingency tables. Each of these are
performed by using the chisq.test() function. 

The basic syntax for this function is (see ?chisq.test for more information): 
 
http://www.r-tutor.com/elementary-statistics/probability-distributions




Binomial coefficients
' n choose k'
nk =n!k! (n-k)!

RSS Higher Certificate Module 4 Linear model
(Royal Statistical Society Professional Exams)
Advanced Data Modelling

Use Simple Linear Regression for calibration and reverse prediction,
Apply and evaluate regression diagnostics with emphasis on leverage and influence points.
Explain the Matrix formulation of the linear model
Understand multiple regression, partial correlation, polynomial regression.
Apply Analysis of Variance : multiple comparisons, two-way ANOVA, interactions
Understand analysis of covariance.
Overview of Generalized Linear Models including nonlinear regression, logistic regression and log-linear models.
1. Simple Linear Regression :

calibration, reverse prediction, regression through the origin, analysis of residuals, regression diagnostics, leverage and influence.
2. Matrix formulation of the linear model :

Multiple regression, partial correlation, polynomial regression.

Regression

Simple linear regression. Least squares estimation.
Multiple linear regression – concepts, interpretation of computer output, inference for regression coefficients using estimates and estimated standard errors from computer output.
Analysis of variance for regression models.
Calculation and interpretation of the multiple correlation coefficient (coefficient of determination).
Simple cases of transforming to linearity.
Correlation

Product-moment correlation (Pearson).
Rank correlation – Spearman’s coefficient.
Calculation and interpretation.
Design of experiments

Reasons for experimentation, causality.
Principles of replication and randomisation, completely randomised design.
Analysis of variance

One-way analysis of variance.
Inference for means and for differences in means
One-way ANOVA, multiple comparisons,
Two-way ANOVA with  interactions,
Analysis of covariance.
Generalized Linear Models

Introduction to Generalized Linear Models including nonlinear regression, logistic regression and log-linear models.



 
Central Limit Theorem
Hypothesis testing and con dence interval construction are based on the Central Limit Theorem.
CLT - see Introductory Data Analysis notes by Dr. Ailish Hannigan.
Can check the CLT using a small simulation example.
We will take 10000 samples of size 5 from data with a uniform distribution and record the means.
When we plot a histogram of the means, should have a normal distribution.
 
means <- numeric(10000)
for(i in 1:10000){
means[i] <- mean(runif(5))
}
hist(means)
 

Recall the Dice experiment in week 8.
 
N=100                                         #number of loops
Avgs=numeric(N)                       #array “Avgs” store the sample means
for( i in 1:N)
              {              Dice=floor(runif(50,min=1,max=7));              Avgs[i]=mean(Dice);
              }
Avgs                                         #print Avgs dataset to screen
 
The Central limit theorem states that.

The “Dice” distribution is a discrete uniform distribution. However

mean(Avgs)                                #compute the mean. Is it roughly what we are expecting?
qqnorm(Avgs)                                #draws a QQ plot that is used to check for normality.
qqline(Avgs)                                #adds trend line to QQplot.
shapiro.test(Avgs)                       #Shapiro Wilk test. Normality is assumed if p-value > 0.05.
                                     


crime=c(761,780 ,593,715,1078,567,456,686,1206,723,261 ,326,282 ,960,489,496,463,1062,805,998,126 ,792,327 ,744,434,178,679,82,339,138,627,930,875,1074,504,635,503,418,402,1023,208,766,762,301 ,372,114,515,264,208,286,2922 )

murder=c(9,11.6 ,10.2 ,8.6 ,13.1 ,5.8 ,6.3 ,5 ,8.9 ,11.4 ,3.8 ,2.3 ,2.9 ,11.4 ,7.5 ,6.4 ,6.6 ,20.3 ,3.9 ,12.7 ,1.6 ,9.8 ,3.4 ,11.3 ,13.5 ,3 ,11.3 ,
1.7 ,3.9 ,2 ,5.3 ,8 ,10.4 ,13.3 ,6 ,8.4 ,4.6 ,6.8 ,3.9 ,10.3 ,3.4 ,10.2 ,11.9 ,3.1 ,8.3 ,3.6 ,5.2 ,4.4 ,6.9 ,3.4 ,8.5 )

pctmetro=c(41.8 ,67.4 ,44.7 ,84.7 ,96.7 ,81.8 ,95.7 ,82.7 ,93 ,67.7 ,74.7 ,43.8 ,30 ,84 ,71.6 ,54.6 ,48.5 ,75 , 96.2 , 92.8 ,35.7 ,
82.7 ,69.3 ,68.3 ,30.7 ,24 ,66.3 ,41.6 ,50.6 ,59.4 ,100 ,56 ,84.8 ,91.7 ,81.3 ,60.1 ,70 ,84.8 ,93.6 ,69.8 ,32.6 ,67.7 ,83.9 ,77.5 ,77.5 ,27 ,83 ,68.1 ,41.8 ,29.7 ,100 )

pctwhite=c(75.2 ,73.5 ,82.9 ,88.6 ,79.3 ,92.5 ,89 ,79.4 ,83.5 ,70.8 ,40.9 ,96.6 ,96.7 ,81 ,90.6 ,90.9 ,91.8 ,66.7 ,91.1 ,68.9 ,98.5 ,83.1 ,94 ,87.6 ,63.3 ,92.6 ,75.2 ,94.2 ,94.3 ,98 ,80.8 ,87.1 ,86.7 ,77.2 ,87.5 ,82.5 ,93.6 ,88.7 ,92.6 ,68.6 ,90.2 ,82.8 ,85.1 ,94.8 ,77.1 ,98.4 ,89.4 ,92.1 ,96.3 ,95.9 ,31.8 )

pcths=c(86.6 ,66.9 ,66.3 ,78.7 ,76.2 ,84.4 ,79.2 ,77.5 ,74.4 ,70.9 ,80.1 ,80.1 ,79.7 ,76.2 ,75.6 ,81.3 ,64.6 ,68.3 ,80 ,78.4 ,78.8 ,76.8 ,82.4 ,73.9 ,64.3 ,81 ,70 ,76.7 ,81.8 , 82.2 ,76.7 ,75.1 ,78.8 ,74.8 ,75.7 ,74.6 ,81.5 ,74.7 ,72 ,68.3 ,77.1 ,67.1 ,72.1 ,85.1 ,75.2 ,80.8 ,83.8 ,78.6 ,66 ,83 ,73.1 )

poverty=c(9.1 ,17.4 ,20 ,15.4 ,18.2 ,9.9 ,8.5 ,10.2 ,17.8 ,13.5 ,8 ,10.3 ,13.1 ,13.6 ,12.2 ,13.1 ,20.4 ,26.4 ,10.7 ,9.7 ,10.7 ,15.4 ,11.6 ,16.1 ,24.7 ,14.9 ,14.4 ,11.2 ,10.3 ,9.9 ,10.9 ,17.4 ,9.8 ,16.4 ,13 ,19.9 ,11.8 ,13.2 ,11.2 ,18.7 ,14.2 ,19.6 ,17.4 ,10.7 ,9.7 ,10 ,12.1 ,12.6 ,22.2 ,13.3 ,26.4 )




\newpage
%------------------------------------------%




%===== %
1. Starting R the first time


When running R from the computer lab, your M drive will be the working directory where your work will be saved by default. You can easily change to another directory at any time by selecting Change Dir... from the File menu. 
You can save your work at any time. Select Save Workspace from the File menu. You will usually save the workspace in the working directory. When you quit R you will be prompted to save your workspace. 


\section{The ``summary()`` command}
``summary()`` is a generic but very useful, function to summarize many types of ``R} objects, including datasets. When used on a dataset, summary returns distributional summaries of variables in the dataset.





\section{A Brief Introduction to fitting Linear Models (Lists)}

A very commonly used statistical procedure is \textbf{simple linear regression}

* ``lm()``
* ``summary()``


\begin{framed}
\begin{verbatim}
Y <- c( )
X <- c( )

plot(X,Y)
cor(X,Y)
lm(Y~X)
\end{verbatim}
\end{framed}
%------------------------%
\begin{framed}
\begin{verbatim}
FitA =lm(Y~X)
summary(FitA)
\end{verbatim}
\end{framed}
%--------------------------------%
Let's look at this summary output in more detail, to see how it is structured. Importantly this object is structured as a list of named components.
\begin{framed}
\begin{verbatim}
names(summary(FitA))
class(summary(FitA))
mode(summary(FitA))
str(summary(FitA))
\end{verbatim}
\end{framed}

%-------------------------------%
The summary of ``FitA} is a data object in it's own right. We will save it under the name ``Sum.FitA} (N.B. The dot in the name has no particular meaning).
\begin{framed}
\begin{verbatim}
Sum.FitA=summary(FitA)
Sum.FitA[1]
Sum.FitA$pvalue
\end{verbatim}
\end{framed}
%------------------------------%
Suppose we wish require the $p-$value for the slope estimate only.
\begin{framed}
\begin{verbatim}
class(Sum.FitA$pvalue)
mode(Sum.FitA$pvalue)
dim(Sum.FitA$pvalue)
\end{verbatim}
\end{framed}
%-------------------------------------------------%

