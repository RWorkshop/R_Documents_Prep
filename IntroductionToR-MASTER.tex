

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Setting up project directories

It is helpful to organize your work in project directories.
Create a directory for your project.
Copy a workspace (a .Rdata file) to the directory
You can then start R by clicking on the .Rdata file's icon
All directory references in the R session will be relative to the project directory. For example, you can read a file 'data.csv' in the directory with


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
http://www.r-tutor.com/elementary-statistics/hypothesis-testing/two-tailed-test-population-proportion
 


Regression more

http://www.ats.ucla.edu/stat/R/dae/rreg.htm


 

Chi-square Tests
Hypothesis test for count data that use the Pearson Chi-square statistic are available in R.
These include the goodness-of-fit tests and those for contingency tables. Each of these are
performed by using the chisq.test() function. 

The basic syntax for this function is (see ?chisq.test for more information): 
 
http://www.r-tutor.com/elementary-statistics/probability-distributions




Binomial coefficients
' n choose k'
nk =n!k! (n-k)!

RSS Higher Certificate Module 4 Linear model
(Royal Statistical Society Professional Exams)
Advanced Data Modelling

Use Simple Linear Regression for calibration and reverse prediction,
Apply and evaluate regression diagnostics with emphasis on leverage and influence points.
Explain the Matrix formulation of the linear model
Understand multiple regression, partial correlation, polynomial regression.
Apply Analysis of Variance : multiple comparisons, two-way ANOVA, interactions
Understand analysis of covariance.
Overview of Generalized Linear Models including nonlinear regression, logistic regression and log-linear models.
1. Simple Linear Regression :

calibration, reverse prediction, regression through the origin, analysis of residuals, regression diagnostics, leverage and influence.
2. Matrix formulation of the linear model :

Multiple regression, partial correlation, polynomial regression.

Regression

Simple linear regression. Least squares estimation.
Multiple linear regression – concepts, interpretation of computer output, inference for regression coefficients using estimates and estimated standard errors from computer output.
Analysis of variance for regression models.
Calculation and interpretation of the multiple correlation coefficient (coefficient of determination).
Simple cases of transforming to linearity.
Correlation

Product-moment correlation (Pearson).
Rank correlation – Spearman’s coefficient.
Calculation and interpretation.
Design of experiments

Reasons for experimentation, causality.
Principles of replication and randomisation, completely randomised design.
Analysis of variance

One-way analysis of variance.
Inference for means and for differences in means
One-way ANOVA, multiple comparisons,
Two-way ANOVA with  interactions,
Analysis of covariance.
Generalized Linear Models

Introduction to Generalized Linear Models including nonlinear regression, logistic regression and log-linear models.



%===== %
1. Starting R the first time


When running R from the computer lab, your M drive will be the working directory where your work will be saved by default. You can easily change to another directory at any time by selecting Change Dir... from the File menu. 
You can save your work at any time. Select Save Workspace from the File menu. You will usually save the workspace in the working directory. When you quit R you will be prompted to save your workspace. 


## The ``summary()`` command}
``summary()`` is a generic but very useful, function to summarize many types of ``R} objects, including datasets. When used on a dataset, summary returns distributional summaries of variables in the dataset.





## A Brief Introduction to fitting Linear Models (Lists)}

A very commonly used statistical procedure is \textbf{simple linear regression}

* ``lm()``
* ``summary()``



<pre><code>
Y <- c( )
X <- c( )

plot(X,Y)
cor(X,Y)
lm(Y~X)
</code></pre>

%------------------------%

<pre><code>
FitA =lm(Y~X)
summary(FitA)
</code></pre>

%--------------------------------%
Let's look at this summary output in more detail, to see how it is structured. Importantly this object is structured as a list of named components.

<pre><code>
names(summary(FitA))
class(summary(FitA))
mode(summary(FitA))
str(summary(FitA))
</code></pre>


%-------------------------------%
The summary of ``FitA} is a data object in it's own right. We will save it under the name ``Sum.FitA} (N.B. The dot in the name has no particular meaning).

<pre><code>
Sum.FitA=summary(FitA)
Sum.FitA[1]
Sum.FitA$pvalue
</code></pre>

%------------------------------%
Suppose we wish require the $p-$value for the slope estimate only.

<pre><code>
class(Sum.FitA$pvalue)
mode(Sum.FitA$pvalue)
dim(Sum.FitA$pvalue)
</code></pre>

%-------------------------------------------------%

