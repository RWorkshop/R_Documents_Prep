\documentclass[a4]{beamer}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{newlfont}
\usepackage{amsmath,amsthm,amsfonts}
%\usepackage{beamerthemesplit}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{mathptmx}  % Font Family
\usepackage{helvet}   % Font Family
\usepackage{color}
\mode<presentation> {
 \usetheme{Frankfurt} % was
 \useinnertheme{rounded}
 \useoutertheme{infolines}
 \usefonttheme{serif}
 %\usecolortheme{wolverine}
% \usecolortheme{rose}
\usefonttheme{structurebold}
}
\setbeamercovered{dynamic}

\title[MA4413]{Statistics for Computing \\ {\normalsize MA4413 Lecture 3A}}
\author[Kevin O'Brien]{Kevin O'Brien \\ {\scriptsize Kevin.obrien@ul.ie}}
\date{Autumn Semester 2013}
\institute[Maths \& Stats]{Dept. of Mathematics \& Statistics, \\ University \textit{of} Limerick}

\renewcommand{\arraystretch}{1.5}

\begin{document}

\begin{frame}
\titlepage
\end{frame}
\frame{
\begin{itemize}
\item Binomial Coefficients / The Choose Operator
\item Definition: The Probability Mass Functions (pmf)
\item Binomial Distribution : Example
\end{itemize}
}
\frame{
\frametitle{Binomial Coefficients}

In the last class, we came across binomial coefficients. Informally, binomial coefficients are the number of ways $k$ items can be selected from a group of $n$ items. 
The binomial coefficient indexed by n and k is usually written as $^nC_k$ or
\[ {n \choose k}\].
$C$ is colloqially known as the ``choose operator".

\[ {n \choose k} = \frac{n!}{k! \times (n-k)!} \]

(We call the operator the choose operator. We will use both notations interchangeably.)
 

}
\frame{
\frametitle{Binomial Coefficients}

\begin{itemize}
\item $n!$ and $k!$ are the coefficients of $n$ and $k$ respectively.
\item $n! = n \times (n-1) \times (n-2) \times \ldots \times 2 \times 1$
\item For example $5! = 5\times4\times3\times2\times1 = 120$
\item $n! = n \times (n-1)!$
\item Importantly $0! = 1$ not 0.
\end{itemize}
\[ {6 \choose 2} = \frac{6!}{2! \times (6-2)!} = \frac{6!}{2! \times 4!}  \]\[\mbox{   } = \frac{6 \times 5 \times 4!}{2! \times 4!} 
 = 30/2 =15 \]
More examples of Binomial coefficients on blackboard.
}
%---------------------------------------------------------------------------%
\frame{
\frametitle{Probability Mass Function}
(Formally defining something mentioned previously)
\begin{itemize} \item a probability mass function (pmf) is a \textbf{\emph{function}}
that gives the probability that a discrete random variable is exactly equal to some
value.
\[P(X=k)\]
\item The probability mass function is often the primary means of defining a discrete
probability distribution
\item It is conventional to present the probability mass function in the form of a table.
\item The p.m.f of a value $k$ is often denoted $f(k)$.
\end{itemize}
}
%--------------------------------------------------------------------------------------%
\frame{
\frametitle{ Binomial Example 1 }
(Revision from Last Class)\\
Suppose a die is tossed 5 times. What is the probability of getting exactly 2 fours?

\textbf{Solution:} This is a binomial experiment in which the number of trials is equal to 5, the number of successes is equal to 2, and the probability of success on a single trial is 1/6 or about 0.167. 
\\
\bigskip
Therefore, the binomial probability is:

\[P(X=2) = ^5C_2 \times (1/6)^2 \times (5/6)^3 = 0.161\]
}

%--------------------------------------------------------------------------------------%
\frame{
\frametitle{ Binomial Example 2 }
Suppose there is a container that contains 6 items.  The probability that any one of these items is defective is 0.3. Suppose all six items are inspected. 
\begin{itemize}
\item What is the probability of 3 defective components?
\item What is the probability of 4 defective components?
\end{itemize}

\[ P(3\text{ defects}) = f(3) = P(X = 3) = {6\choose 3}0.3^3 (1-0.3)^{6-3} = 0.1852 \]
\[ P(4\text{ defects}) = f(4) = P(X = 4) = {6\choose 4}0.3^4 (1-0.3)^{6-4} = 0.0595 \]
}

%--------------------------------------------------------------------------------------%
\frame{
\frametitle{Probability Tables}
In the \textbf{Sulis} workspace there are two important tables used for this part of the course.


This class will feature a demonstration on how to read those tables.
\begin{itemize}
\item The Cumulative Binomial Tables (Murdoch Barnes Tables 1)
\item The Cumulative Poisson Tables (Murdoch Barnes Tables 2)
\end{itemize}

Please get a copy of each as soon as possible.

}

%---------------------------------------------------------------------------%
\frame{
\frametitle{Probability Tables}
\begin{itemize}
\item For some value $r$ the tables record the probability of $P(X \geq r)$.
\item The Student is required to locate the appropriate column based on the parameter values for the distribution in question.
\item A copy of the Murdoch Barnes Tables will be furnished to the student in the End of Year Exam. The Tables are not required for the first mid-term exam.
\item Knowledge of the sample space, partitioning of the sample points, and the complement rule are advised.
\end{itemize}
}
%---------------------------------------------------------------------------%


\frame{
\frametitle{Binomial Distribution : Using Tables}
It is estimated by a particular bank that 25\% of credit card customers pay only the minimum amount due on their monthly credit card bill and do not pay the total amount due. 50 credit card customers are randomly selected.
\begin{enumerate}
\item (3 marks)	What is the probability that 9 or more of the selected customers pay only the minimum amount due?
\item (3 marks) What is the probability that less than 6 of the selected customers pay only the minimum amount due?
\item (3 marks)	What is the probability that more than 5 but less than 10 of the selected customers pay only the minimum amount due?
\end{enumerate}

}

\frame{
\frametitle{Binomial Distribution : Using Tables}
Demonstration on Blackboard re: how to use tables in class.
\begin{enumerate}
\item $P(X \geq 9) = 0.9084$
\item $P(X < 6) = 1- P(X \geq 6) =1 - 0.9930 = 0.0070$
\item $P(6 \leq X \leq 9) = P(X \geq 6) - P(X \geq 10) = 0.9930 - 0.8363 = 0.1567$
\end{enumerate}

}


%------------------------------------------------------------------%
\frame{
\frametitle{Binomial Distribution: Expected Value and Variance}


If the random variable X has a binomial distribution with parameters n
and p, we write
\[ X \sim B(n,p) \]

Expectation and Variance
If $X \sim B(n,p)$, then:

\begin{itemize}
\item Expected Value of X : $E(X) = np$
\item Variance of X : $Var(X) = np(1-p)$
\end{itemize}

Suppose n=3 and p=0.5 
Then $E(X) = 1.5$ and $V(X) = 0.75$.

Remark: Referring to the expected value and variance may be used to validate
the assumption of a binomial distribution.

}
%---------------------------------------------------------------------------%
\frame{
\frametitle{The Geometric Distribution}
\begin{itemize}
\item The Geometric distribution is related to the Binomial distribution in that
both are based on independent trials in which the probability of success
is constant and equal to p.
\item However, a Geometric random variable is the number of trials until the
first failure, whereas a Binomial random variable is the number of
successes in n trials.
\item The Geometric distributions is often used in IT security applications.
\end{itemize}
}
%---------------------------------------------------------------------------%
\frame{
\frametitle{The Geometric Distribution}

Suppose that a random experiment has two possible outcomes, success
with probability p and failure with probability 1-p .


The experiment is repeated until a success happens. The number of
trials before the success is a random variable X computed as follows

\[P(X = k) = (1-p)^{(k-1)}\times p \]


(i.e. The probability that first success is on the k-th trial)
}


%---------------------------------------------------------------------------%
\frame{
\frametitle{The Geometric Distribution: Notation}

If X has a geometric distribution with parameter p, we write
\[X \sim Geo(p) \]
Expectation and Variance
If $X \sim Geo(p)$, then:

\begin{itemize}
\item Expected Value of X : E(X) = 1/p
\item Variance of X : Var(X) = $(1-p)/p^2$.
\end{itemize}
}




%---------------------------------------------------------------------%
\begin{frame}
\frametitle{The Cumulative Distribution Function}
\begin{itemize}
\item The Cumulative Distribution Function, denoted $F(x)$, is a common way that the probabilities
of a random variable (both discrete and continuous) can be summarized.
\item The Cumulative Distribution Function, which also can be
described by a formula or summarized in a table, is defined as:
\[F(x) = P(X \leq x) \]
\item The notation for a cumulative distribution function, F(x), entails using a capital
"F".  (The notation for a probability mass or density function, f(x), i.e. using a lowercase "f". The notation is not interchangeable.
\end{itemize}
\end{frame}

%---------------------------------------------------------------------%
\begin{frame}
\frametitle{Useful Results}
(Demonstration on the blackboard re: partitioning of the sample space, using examples on next slide)
\begin{itemize}
\item $P(X \leq 1) = P(X=0) + P(X=1)$
\item $P(X \leq r) = P(X=0)+ P(X=1) + \ldots P(X= r)$
\item $P(X \leq 0) = P(X=0)$
\item $P(X = r) = P(X \geq r ) - P(X \geq r + 1)$
\item \textbf{Complement Rule}: $P(X \leq r-1) = P(X < r) = 1 - P(X \geq r)$
\item \textbf{Interval Rule}:$ P(a \leq X \leq  b)= P(X \geq a) - P(X \geq b + 1).$
\end{itemize}
For the binomial distribution, if the probability of success is greater than 0.5, instead of
considering the number of successes, to use the table we consider
the number of failures.
\end{frame}
%---------------------------------------------------------------------%


%---------------------------------------------------------------------%
\begin{frame}
\frametitle{Binomial Example 1}
Suppose a signal of 100 bits is transmitted and the probability of
sending a bit correctly is 0.9. What is the probability of
\begin{enumerate}
\item at least 10 errors
\item exactly 7 errors
\item Between 5 and 15 errors (inclusively).
\end{enumerate}
\end{frame}
%---------------------------------------------------------------------%
\begin{frame}
\frametitle{Binomial Example 1}
\begin{itemize}
\item Since the probability of success is 0.9. We consider the distribution
of the number of failures (errors).
\item We reverse the definition of `success' and `failure'. Success is now defined as an error.
\item The probability that a bit is sent incorrectly is 0.1.
\item Let X be the total number of errors. $X \sim B(100, 0.1)$.
\item Answer : $P(X \geq 10) = 0.5487$.
\item $P(X = 7)=P(X \geq 7) - P(X \geq 8) =0.8828 - 0.7939 = 0.0889$.
\item $P(5 \leq X  \leq 15) = P(X \geq 5) - P(X \geq 16) =0.9763 - 0.0399 = 0.9364$
\end{itemize}
\end{frame}


\end{document}
