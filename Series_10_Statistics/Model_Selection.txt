

### Model Selection}
There are many important methodologies for determining which combination of predictor variables bests describes a response variable. You will meet this in future modules.
We will use two simple ones for this module only.

* Adjusted Râ€“squared value
* The Akaike Information Criterion (AIC)



The adjusted R-square value is found on the summary output for a fitted model. It is called ***adjusted*** because it takes into account the number of predictor variables being used. The law of parsimony states the simplest model that adequately explains the outcomes is the best. The candidate model with the higher adjusted R squared is considered preferable.

The AIC is a model selection metric often used in statistics.It is computed using the R command
***AIC()***.The candidate model with the smallest AIC value is considered preferable.


```{r}
fitA = lm(Sepal.Length ~ Sepal.Width + Petal.Width)
fitB = lm(Sepal.Length ~ Sepal.Width + Petal.Length)

summary(fitA)$adj.r.squared
summary(fitB)$adj.r.squared

AIC(fitA)
AIC(fitB)
```


%----------------------------------------------------%
\end{document} 
